nohup: ignoring input
/opt/caoshujian/stack_gan/code/miscc/config.py:101: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
Using config:
{'CONFIG_NAME': '3stages',
 'CUDA': True,
 'DATASET_NAME': 'CUHK',
 'DATA_DIR': 'D:/NEW_HDGAN/StackGAN-v2-master/data/birds',
 'EMBEDDING_TYPE': 'cnn-rnn',
 'GAN': {'B_CONDITION': True,
         'DF_DIM': 64,
         'EMBEDDING_DIM': 128,
         'GF_DIM': 64,
         'NETWORK_TYPE': 'default',
         'R_NUM': 2,
         'Z_DIM': 100},
 'GPU_ID': '0',
 'TEST': {'B_EXAMPLE': True, 'SAMPLE_NUM': 30000},
 'TEXT': {'DIMENSION': 768},
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'COLOR_LOSS': 0.0,
                     'KL': 2.0,
                     'MS_LOSS': 2.0,
                     'UNCOND_LOSS': 1.0},
           'DISCRIMINATOR_LR': 2e-05,
           'FLAG': True,
           'GENERATOR_LR': 0.0002,
           'MAX_EPOCH': 600,
           'NET_D': '',
           'NET_G': '',
           'SNAPSHOT_INTERVAL': 1000,
           'VIS_COUNT': 64},
 'TREE': {'BASE_SIZE': 64,
          'BASE_SIZE_1': 64,
          'BASE_SIZE_2': 32,
          'BRANCH_NUM': 3},
 'WORKERS': 4}
/home/caoshujian/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Load filenames from: /opt/caoshujian/HD_GAN/Data/train/train_files_1w.pickle (10000)
DataParallel(
  (module): G_NET(
    (ca_net): CA_NET(
      (fc): Linear(in_features=768, out_features=512, bias=True)
      (relu): GLU()
    )
    (h_net1): INIT_STAGE_G(
      (fc): Sequential(
        (0): Linear(in_features=228, out_features=16384, bias=False)
        (1): BatchNorm1d(16384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (upsample1): Sequential(
        (0): Interpolate()
        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample2): Sequential(
        (0): Interpolate()
        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample3): Sequential(
        (0): Interpolate()
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample4): Sequential(
        (0): Interpolate()
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net1): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
    (h_net2): NEXT_STAGE_G(
      (jointConv): Sequential(
        (0): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (residual): Sequential(
        (0): ResBlock(
          (block): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): ResBlock(
          (block): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (upsample): Sequential(
        (0): Interpolate()
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net2): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
    (h_net3): NEXT_STAGE_G(
      (jointConv): Sequential(
        (0): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (residual): Sequential(
        (0): ResBlock(
          (block): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): ResBlock(
          (block): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (upsample): Sequential(
        (0): Interpolate()
        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net3): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
  )
)
# of netsD 3
uncon_loss: tensor(3.0452, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(3.1152, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.9305, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.5135, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.9986, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.5450, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.3534, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(12.2877, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.5577, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.4482, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(20.5142, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(5.2749, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(5.5932, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(21.4217, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6550, device='cuda:0', grad_fn=<MulBackward0>)
uncon_loss: tensor(3.2041, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.6013, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.9964, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.4142, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(3.0640, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.3517, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.5604, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.2099, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.3165, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.0790, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.7164, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6508, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.0624, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8601, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8013, device='cuda:0', grad_fn=<MulBackward0>)
[1/600][312]  Loss_D: 0.00 Loss_G: 27.96 Loss_KL: 3.56 lr_g: 0.00020000 lr_d: 0.00002000 Time: 72.24s
                                  
uncod_G: tensor(1.1746, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.4716, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8697, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.4165, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7315, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7306, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.2547, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.2008, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6624, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.0506, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.4039, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.4288, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.3271, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6334, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.3653, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.0506, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0927, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6714, device='cuda:0', grad_fn=<MulBackward0>)
[2/600][312]  Loss_D: 0.00 Loss_G: 25.29 Loss_KL: 2.15 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.48s
                                  
uncod_G: tensor(1.2055, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.5439, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5816, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5611, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.5161, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5777, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.8329, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8921, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7226, device='cuda:0', grad_fn=<MulBackward0>)
[3/600][312]  Loss_D: 0.00 Loss_G: 24.33 Loss_KL: 1.30 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.55s
                                  
uncod_G: tensor(1.1131, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.5199, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.0929, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.3720, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7880, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.4320, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.2009, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7377, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.9959, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.2108, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6230, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.0178, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.3593, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7418, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.4270, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6500, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9040, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5363, device='cuda:0', grad_fn=<MulBackward0>)
[4/600][312]  Loss_D: 0.00 Loss_G: 25.16 Loss_KL: 1.30 lr_g: 0.00020000 lr_d: 0.00002000 Time: 70.60s
                                  
uncod_G: tensor(1.2402, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7833, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.2103, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6033, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9092, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7492, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.3532, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7883, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5226, device='cuda:0', grad_fn=<MulBackward0>)
[5/600][312]  Loss_D: 0.00 Loss_G: 24.33 Loss_KL: 1.23 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.58s
                                  
uncon_loss: tensor(3.1142, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2918, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.8281, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1808, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.5627, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1565, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.4389, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8021, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.8998, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.7480, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8876, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.1979, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.6348, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0909, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6068, device='cuda:0', grad_fn=<MulBackward0>)
uncon_loss: tensor(2.8806, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.3093, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.7708, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.3017, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.5086, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2153, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.4910, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8092, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5066, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.9529, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7812, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7002, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.0551, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0780, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.4684, device='cuda:0', grad_fn=<MulBackward0>)
[6/600][312]  Loss_D: 0.00 Loss_G: 25.29 Loss_KL: 1.20 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.60s
                                  
uncod_G: tensor(1.4503, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9341, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5301, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6471, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8757, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7216, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5335, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9376, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.3608, device='cuda:0', grad_fn=<MulBackward0>)
[7/600][312]  Loss_D: 0.00 Loss_G: 27.37 Loss_KL: 1.29 lr_g: 0.00020000 lr_d: 0.00002000 Time: 70.14s
                                  
uncod_G: tensor(1.4448, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7449, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.4377, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6261, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7487, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1186, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.4961, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.2800, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8977, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5771, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6445, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6499, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.8064, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7667, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0346, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(4.2895, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.9538, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6834, device='cuda:0', grad_fn=<MulBackward0>)
[8/600][312]  Loss_D: 0.00 Loss_G: 26.12 Loss_KL: 1.28 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.57s
                                  
uncod_G: tensor(1.5094, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9626, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5109, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5105, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7622, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5992, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.9078, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9676, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.9826, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.4068, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7742, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.3546, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5642, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8236, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7342, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.4048, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6372, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5286, device='cuda:0', grad_fn=<MulBackward0>)
[9/600][312]  Loss_D: 0.00 Loss_G: 26.43 Loss_KL: 1.39 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.59s
                                  
uncod_G: tensor(1.4523, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7429, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.4672, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.3815, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8348, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8335, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.4663, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7829, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7196, device='cuda:0', grad_fn=<MulBackward0>)
[10/600][312]  Loss_D: 0.00 Loss_G: 26.82 Loss_KL: 1.37 lr_g: 0.00020000 lr_d: 0.00002000 Time: 70.17s
                                  
uncon_loss: tensor(2.9932, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2805, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.6811, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2565, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.3080, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1399, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.4650, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.1725, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8148, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.0686, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7061, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1304, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.9888, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.2787, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0152, device='cuda:0', grad_fn=<MulBackward0>)
uncon_loss: tensor(2.5788, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.3438, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.4961, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.3799, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.0800, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2391, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.5953, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6929, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7256, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.3097, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0160, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0776, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.7024, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.8621, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2941, device='cuda:0', grad_fn=<MulBackward0>)
[11/600][312]  Loss_D: 0.00 Loss_G: 25.44 Loss_KL: 1.49 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.59s
                                  
uncod_G: tensor(1.3091, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6588, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7320, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.3012, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6189, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0204, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6039, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8085, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7903, device='cuda:0', grad_fn=<MulBackward0>)
[12/600][312]  Loss_D: 0.00 Loss_G: 27.97 Loss_KL: 1.46 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.63s
                                  
uncod_G: tensor(1.3920, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8321, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7163, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5577, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7128, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.5931, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.6101, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.4298, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2153, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.4803, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8011, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8628, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.8084, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7380, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4734, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.8965, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9354, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4114, device='cuda:0', grad_fn=<MulBackward0>)
[13/600][312]  Loss_D: 0.00 Loss_G: 28.91 Loss_KL: 1.51 lr_g: 0.00020000 lr_d: 0.00002000 Time: 70.19s
                                  
uncod_G: tensor(1.4082, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.5055, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8923, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6505, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7832, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0285, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.0285, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.2774, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2751, device='cuda:0', grad_fn=<MulBackward0>)
[14/600][312]  Loss_D: 0.00 Loss_G: 28.92 Loss_KL: 1.67 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.61s
                                  
uncod_G: tensor(1.3856, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8413, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.9500, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.7679, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9921, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0765, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.5489, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.6008, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1906, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.4008, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6698, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8091, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6840, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8946, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6510, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.1012, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.3954, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7878, device='cuda:0', grad_fn=<MulBackward0>)
[15/600][312]  Loss_D: 0.00 Loss_G: 27.60 Loss_KL: 1.74 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.58s
                                  
uncon_loss: tensor(2.8714, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2709, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.7430, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2554, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.2183, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1250, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.4547, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8636, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.9670, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.7473, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8373, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1837, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(4.3682, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.6680, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1985, device='cuda:0', grad_fn=<MulBackward0>)
[16/600][312]  Loss_D: 0.00 Loss_G: 28.28 Loss_KL: 1.81 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.61s
                                  
uncod_G: tensor(1.4327, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6898, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6743, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5208, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6809, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0416, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.9737, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0236, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2377, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.4419, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7341, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8069, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.3743, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6064, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7972, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5273, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7990, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5838, device='cuda:0', grad_fn=<MulBackward0>)
[17/600][312]  Loss_D: 0.00 Loss_G: 29.12 Loss_KL: 1.82 lr_g: 0.00020000 lr_d: 0.00002000 Time: 70.14s
                                  
uncod_G: tensor(1.4520, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7149, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8672, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6341, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7015, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.3091, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.7039, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0857, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1307, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6653, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.2052, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4234, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.0311, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8865, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1526, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.6604, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.3470, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2412, device='cuda:0', grad_fn=<MulBackward0>)
[18/600][312]  Loss_D: 0.00 Loss_G: 27.97 Loss_KL: 2.05 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.60s
                                  
uncod_G: tensor(1.4379, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7392, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7971, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5378, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6867, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.3592, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.7802, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.9206, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.9347, device='cuda:0', grad_fn=<MulBackward0>)
[19/600][312]  Loss_D: 0.00 Loss_G: 33.83 Loss_KL: 2.05 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.58s
                                  
uncod_G: tensor(1.5759, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9904, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8954, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6503, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7724, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.3383, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.6559, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.8201, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4242, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.4495, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0234, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8513, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.8858, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.1520, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.9269, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.5196, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.3085, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0743, device='cuda:0', grad_fn=<MulBackward0>)
[20/600][312]  Loss_D: 0.00 Loss_G: 34.01 Loss_KL: 2.17 lr_g: 0.00020000 lr_d: 0.00002000 Time: 70.11s
                                  
uncon_loss: tensor(2.7587, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2369, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.5974, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2759, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(1.7341, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1292, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.5618, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9424, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0851, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.8742, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7090, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.6914, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.2294, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.0636, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.6421, device='cuda:0', grad_fn=<MulBackward0>)
[21/600][312]  Loss_D: 0.00 Loss_G: 33.75 Loss_KL: 2.37 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.59s
                                  
uncod_G: tensor(1.4341, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8522, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4326, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6406, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8523, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.3515, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.6232, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.8263, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.6840, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5450, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8614, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7381, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.2751, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6654, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2435, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.5253, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.7862, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.5408, device='cuda:0', grad_fn=<MulBackward0>)
[22/600][312]  Loss_D: 0.00 Loss_G: 31.10 Loss_KL: 2.27 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.62s
                                  
uncod_G: tensor(1.3748, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7591, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5977, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.2801, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.1841, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1413, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(5.8284, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(5.9915, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2629, device='cuda:0', grad_fn=<MulBackward0>)
[23/600][312]  Loss_D: 0.00 Loss_G: 37.23 Loss_KL: 2.26 lr_g: 0.00020000 lr_d: 0.00002000 Time: 70.14s
                                  
uncod_G: tensor(1.3370, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7907, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.5675, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5882, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8480, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.7044, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.2845, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.4897, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4636, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5151, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9686, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.9240, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.7417, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8178, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2275, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6746, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8177, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4263, device='cuda:0', grad_fn=<MulBackward0>)
[24/600][312]  Loss_D: 0.00 Loss_G: 28.87 Loss_KL: 2.57 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.60s
                                  
uncod_G: tensor(1.4164, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8148, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1306, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.1845, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.3027, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.3367, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(5.0401, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(5.4082, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2110, device='cuda:0', grad_fn=<MulBackward0>)
[25/600][312]  Loss_D: 0.00 Loss_G: 31.95 Loss_KL: 2.42 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.59s
                                  
uncon_loss: tensor(2.6496, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.3062, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.4178, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1985, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(1.4327, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(1.5743, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.7068, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0170, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6315, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.7622, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.3454, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2429, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(4.7564, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(5.5607, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0859, device='cuda:0', grad_fn=<MulBackward0>)
uncon_loss: tensor(2.6754, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1929, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.7819, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2511, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.1457, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2331, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.6771, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8948, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.6003, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.3698, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0401, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4540, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(4.1296, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.7791, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1944, device='cuda:0', grad_fn=<MulBackward0>)
[26/600][312]  Loss_D: 0.00 Loss_G: 33.34 Loss_KL: 2.57 lr_g: 0.00020000 lr_d: 0.00002000 Time: 70.15s
                                  
uncod_G: tensor(1.3075, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8052, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.3356, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5438, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8020, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1515, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.1778, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.6323, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4986, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.4059, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7260, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.9912, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.9513, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9687, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0843, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.3800, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.4802, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0671, device='cuda:0', grad_fn=<MulBackward0>)
[27/600][312]  Loss_D: 0.00 Loss_G: 36.11 Loss_KL: 2.86 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.58s
                                  
uncod_G: tensor(1.5265, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7578, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.5722, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6576, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9288, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1980, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(4.9292, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(5.5107, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.7181, device='cuda:0', grad_fn=<MulBackward0>)
[28/600][312]  Loss_D: 0.00 Loss_G: 30.16 Loss_KL: 2.80 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.61s
                                  
uncod_G: tensor(1.6881, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9297, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0154, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.3777, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.5221, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.8118, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6767, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0285, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4903, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5144, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7458, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2631, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.8818, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.3189, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1029, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.2362, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.6289, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4871, device='cuda:0', grad_fn=<MulBackward0>)
[29/600][312]  Loss_D: 0.00 Loss_G: 34.78 Loss_KL: 2.79 lr_g: 0.00020000 lr_d: 0.00002000 Time: 70.17s
                                  
uncod_G: tensor(1.5081, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8858, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1422, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.5765, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6932, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.6010, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.8332, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.5162, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1459, device='cuda:0', grad_fn=<MulBackward0>)
[30/600][312]  Loss_D: 0.00 Loss_G: 31.98 Loss_KL: 3.16 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.59s
                                  
uncon_loss: tensor(3.0019, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2861, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.7581, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2644, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.2304, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2182, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.4141, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.8200, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2946, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.4661, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.2777, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.6195, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(8.2585, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(7.9652, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.4253, device='cuda:0', grad_fn=<MulBackward0>)
uncon_loss: tensor(2.7978, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2288, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.4792, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2365, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.0769, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.0185, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.5469, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9658, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2274, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.3122, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.9017, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0977, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(7.9152, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(8.0126, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0362, device='cuda:0', grad_fn=<MulBackward0>)
[31/600][312]  Loss_D: 0.00 Loss_G: 36.63 Loss_KL: 2.78 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.59s
                                  
uncod_G: tensor(1.3561, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7805, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1719, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.8637, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.3003, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.0431, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.2742, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.6193, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.1782, device='cuda:0', grad_fn=<MulBackward0>)
[32/600][312]  Loss_D: 0.00 Loss_G: 38.49 Loss_KL: 3.31 lr_g: 0.00020000 lr_d: 0.00002000 Time: 69.59s
                                  
uncod_G: tensor(1.5479, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.7100, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.9301, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.9516, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.6408, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.2375, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(5.4524, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(6.1043, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.5476, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.6001, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(2.9684, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(3.8756, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.1146, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.1323, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.3220, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.3446, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.5329, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(4.6126, device='cuda:0', grad_fn=<MulBackward0>)
