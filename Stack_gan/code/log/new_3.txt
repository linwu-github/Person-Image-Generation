nohup: ignoring input
/opt/caoshujian/stack_gan/code/miscc/config.py:101: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
Using config:
{'CONFIG_NAME': '3stages',
 'CUDA': True,
 'DATASET_NAME': 'CUHK',
 'DATA_DIR': 'D:/NEW_HDGAN/StackGAN-v2-master/data/birds',
 'EMBEDDING_TYPE': 'cnn-rnn',
 'GAN': {'B_CONDITION': True,
         'DF_DIM': 64,
         'EMBEDDING_DIM': 128,
         'GF_DIM': 64,
         'NETWORK_TYPE': 'default',
         'R_NUM': 2,
         'Z_DIM': 100},
 'GPU_ID': '0',
 'TEST': {'B_EXAMPLE': True, 'SAMPLE_NUM': 30000},
 'TEXT': {'DIMENSION': 768},
 'TRAIN': {'BATCH_SIZE': 32,
           'COEFF': {'COLOR_LOSS': 0.0,
                     'KL': 2.0,
                     'MS_LOSS': 1.0,
                     'UNCOND_LOSS': 1.0},
           'DISCRIMINATOR_LR': 2e-05,
           'FLAG': True,
           'GENERATOR_LR': 0.0002,
           'MAX_EPOCH': 600,
           'NET_D': '',
           'NET_G': '',
           'SNAPSHOT_INTERVAL': 1000,
           'VIS_COUNT': 64},
 'TREE': {'BASE_SIZE': 64,
          'BASE_SIZE_1': 64,
          'BASE_SIZE_2': 32,
          'BRANCH_NUM': 3},
 'WORKERS': 4}
/home/caoshujian/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Load filenames from: /opt/caoshujian/HD_GAN/Data/train/train_files_1w.pickle (10000)
DataParallel(
  (module): G_NET(
    (ca_net): CA_NET(
      (fc): Linear(in_features=768, out_features=512, bias=True)
      (relu): GLU()
    )
    (h_net1): INIT_STAGE_G(
      (fc): Sequential(
        (0): Linear(in_features=228, out_features=16384, bias=False)
        (1): BatchNorm1d(16384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (upsample1): Sequential(
        (0): Interpolate()
        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample2): Sequential(
        (0): Interpolate()
        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample3): Sequential(
        (0): Interpolate()
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample4): Sequential(
        (0): Interpolate()
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net1): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
    (h_net2): NEXT_STAGE_G(
      (jointConv): Sequential(
        (0): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (residual): Sequential(
        (0): ResBlock(
          (block): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): ResBlock(
          (block): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (upsample): Sequential(
        (0): Interpolate()
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net2): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
    (h_net3): NEXT_STAGE_G(
      (jointConv): Sequential(
        (0): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (residual): Sequential(
        (0): ResBlock(
          (block): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): ResBlock(
          (block): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (upsample): Sequential(
        (0): Interpolate()
        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net3): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
  )
)
# of netsD 3
uncon_loss: tensor(2.9180, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(3.3000, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(3.1421, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.6088, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(3.1771, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(3.0529, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.3076, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(1.8864, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.3517, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(1.8112, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.6280, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.1971, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.7786, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(6.2375, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.8226, device='cuda:0', grad_fn=<MulBackward0>)
uncon_loss: tensor(2.7112, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2799, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.9185, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.3613, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.2693, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.3963, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.6523, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.0784, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.9453, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.2393, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.3160, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.9532, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(4.6649, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.3195, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.9194, device='cuda:0', grad_fn=<MulBackward0>)
[1/600][312]  Loss_D: 13.40 Loss_G: 29.70 Loss_KL: 3.07 lr_g: 0.00020000 lr_d: 0.00002000 Time: 108.30s
                                  
uncod_G: tensor(0.1683, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.5775, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.8562, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0419, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.6564, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.7658, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0047, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.4821, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.8160, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0692, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4876, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0091, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.2282, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3787, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3686, device='cuda:0', grad_fn=<MulBackward0>)
[2/600][312]  Loss_D: 0.00 Loss_G: 6.02 Loss_KL: 0.24 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.53s
                                  
uncod_G: tensor(0.0501, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3794, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0055, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3325, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3381, device='cuda:0', grad_fn=<MulBackward0>)
[3/600][312]  Loss_D: 0.00 Loss_G: 4.42 Loss_KL: 0.10 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.57s
                                  
uncod_G: tensor(0.0374, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0986, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4343, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0044, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3553, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1131, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3620, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0288, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4341, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0025, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3542, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0774, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3582, device='cuda:0', grad_fn=<MulBackward0>)
[4/600][312]  Loss_D: 0.00 Loss_G: 4.57 Loss_KL: 0.05 lr_g: 0.00020000 lr_d: 0.00002000 Time: 61.66s
                                  
uncon_loss: tensor(2.7052, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1900, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.4377, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2177, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(1.9538, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.3388, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.8081, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.3436, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.0736, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.8311, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.6455, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.9855, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(4.5493, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.7545, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.1904, device='cuda:0', grad_fn=<MulBackward0>)
[5/600][312]  Loss_D: 13.48 Loss_G: 29.27 Loss_KL: 3.01 lr_g: 0.00020000 lr_d: 0.00002000 Time: 105.37s
                                  
uncod_G: tensor(0.3526, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(1.0470, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.9263, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.1009, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.9143, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.8588, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0214, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.6789, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.6775, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0942, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4977, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0113, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3587, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2935, device='cuda:0', grad_fn=<MulBackward0>)
[6/600][312]  Loss_D: 0.00 Loss_G: 5.24 Loss_KL: 0.18 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.67s
                                  
uncod_G: tensor(0.0597, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3797, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0059, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3086, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1222, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2579, device='cuda:0', grad_fn=<MulBackward0>)
[7/600][312]  Loss_D: 0.00 Loss_G: 4.28 Loss_KL: 0.09 lr_g: 0.00020000 lr_d: 0.00002000 Time: 61.18s
                                  
uncod_G: tensor(0.0419, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0753, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3510, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0039, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2576, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2304, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0343, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3428, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0033, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2516, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1938, device='cuda:0', grad_fn=<MulBackward0>)
[8/600][312]  Loss_D: 0.00 Loss_G: 3.88 Loss_KL: 0.07 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.64s
                                  
uncod_G: tensor(0.0312, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3511, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0030, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2848, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2738, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0265, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0414, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3251, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0026, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0412, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2470, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0605, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2259, device='cuda:0', grad_fn=<MulBackward0>)
[9/600][312]  Loss_D: 0.00 Loss_G: 4.09 Loss_KL: 0.04 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.57s
                                  
uncon_loss: tensor(2.4483, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1118, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.4320, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2005, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(1.8310, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2595, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.9295, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.2864, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.7529, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.3914, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.1152, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.2801, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(7.6008, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(6.5600, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.2801, device='cuda:0', grad_fn=<MulBackward0>)
[10/600][312]  Loss_D: 12.75 Loss_G: 37.19 Loss_KL: 3.14 lr_g: 0.00020000 lr_d: 0.00002000 Time: 106.04s
                                  
uncod_G: tensor(0.1487, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.4453, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.8367, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0349, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.4390, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.6597, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0088, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.4345, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.6189, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0725, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1570, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.5581, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0115, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4908, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0030, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.2533, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4345, device='cuda:0', grad_fn=<MulBackward0>)
[11/600][312]  Loss_D: 0.00 Loss_G: 4.91 Loss_KL: 0.19 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.61s
                                  
uncod_G: tensor(0.0466, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3026, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0049, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2015, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1410, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2083, device='cuda:0', grad_fn=<MulBackward0>)
[12/600][312]  Loss_D: 0.00 Loss_G: 4.01 Loss_KL: 0.10 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.59s
                                  
uncod_G: tensor(0.0403, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3164, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0056, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1923, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1477, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1718, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0379, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.6032, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0051, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0692, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.5046, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4765, device='cuda:0', grad_fn=<MulBackward0>)
[13/600][312]  Loss_D: 0.00 Loss_G: 3.79 Loss_KL: 0.06 lr_g: 0.00020000 lr_d: 0.00002000 Time: 61.21s
                                  
uncod_G: tensor(0.0281, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3796, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0033, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0442, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2728, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2708, device='cuda:0', grad_fn=<MulBackward0>)
[14/600][312]  Loss_D: 0.00 Loss_G: 4.36 Loss_KL: 0.04 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.65s
                                  
uncon_loss: tensor(2.8580, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2649, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.5818, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.2438, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(1.3585, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(1.8635, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.7658, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.4350, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.1794, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.9427, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.8633, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.2887, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(5.3685, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(5.8823, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.0656, device='cuda:0', grad_fn=<MulBackward0>)
uncon_loss: tensor(2.2978, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1598, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(2.2727, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1218, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(1.6009, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1997, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.9457, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.3713, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.9267, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.4396, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.5712, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.9207, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(4.3569, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(4.8992, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.9640, device='cuda:0', grad_fn=<MulBackward0>)
[15/600][312]  Loss_D: 11.27 Loss_G: 34.90 Loss_KL: 3.33 lr_g: 0.00020000 lr_d: 0.00002000 Time: 105.36s
                                  
uncod_G: tensor(0.1548, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.4166, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.6329, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0208, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.5186, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0030, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4602, device='cuda:0', grad_fn=<MulBackward0>)
[16/600][312]  Loss_D: 0.00 Loss_G: 5.37 Loss_KL: 0.18 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.67s
                                  
uncod_G: tensor(0.0860, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1814, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4768, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0118, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1339, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3485, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0023, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1993, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3031, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0562, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1150, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2716, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0066, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1544, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1538, device='cuda:0', grad_fn=<MulBackward0>)
[17/600][312]  Loss_D: 0.00 Loss_G: 4.34 Loss_KL: 0.09 lr_g: 0.00020000 lr_d: 0.00002000 Time: 61.20s
                                  
uncod_G: tensor(0.0415, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4151, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0053, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3630, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3383, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0377, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4444, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0060, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3414, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3279, device='cuda:0', grad_fn=<MulBackward0>)
[18/600][312]  Loss_D: 0.00 Loss_G: 4.21 Loss_KL: 0.06 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.61s
                                  
uncod_G: tensor(0.0311, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2004, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0047, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0513, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1271, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0757, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1284, device='cuda:0', grad_fn=<MulBackward0>)
[19/600][312]  Loss_D: 0.00 Loss_G: 3.93 Loss_KL: 0.03 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.64s
                                  
uncon_loss: tensor(2.6316, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1809, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(1.7386, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(1.9344, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(0.9061, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(1.7227, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.8522, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.2602, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.1264, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(4.3009, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(5.0917, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.2021, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(5.7602, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(6.3104, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.0500, device='cuda:0', grad_fn=<MulBackward0>)
uncon_loss: tensor(2.4334, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.0823, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(1.8870, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.1477, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(1.0047, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(1.6867, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.9992, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.3531, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.2509, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.8219, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(5.1258, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.2755, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(8.5773, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(7.4947, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.0717, device='cuda:0', grad_fn=<MulBackward0>)
[20/600][312]  Loss_D: 13.23 Loss_G: 42.10 Loss_KL: 3.59 lr_g: 0.00020000 lr_d: 0.00002000 Time: 106.03s
                                  
uncod_G: tensor(0.1247, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.3182, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.7692, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0209, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.2137, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.5135, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0084, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.3579, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4515, device='cuda:0', grad_fn=<MulBackward0>)
[21/600][312]  Loss_D: 0.00 Loss_G: 5.19 Loss_KL: 0.20 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.71s
                                  
uncod_G: tensor(0.0746, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.5615, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0103, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1094, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3794, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0038, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1862, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3230, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0573, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.5700, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0064, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3845, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3867, device='cuda:0', grad_fn=<MulBackward0>)
[22/600][312]  Loss_D: 0.00 Loss_G: 4.03 Loss_KL: 0.10 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.60s
                                  
uncod_G: tensor(0.0417, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0801, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2972, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0051, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1515, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0947, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1380, device='cuda:0', grad_fn=<MulBackward0>)
[23/600][312]  Loss_D: 0.00 Loss_G: 3.89 Loss_KL: 0.06 lr_g: 0.00020000 lr_d: 0.00002000 Time: 61.20s
                                  
uncod_G: tensor(0.0373, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3168, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0055, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1946, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1873, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0291, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2205, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0038, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0425, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1193, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0009, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1182, device='cuda:0', grad_fn=<MulBackward0>)
[24/600][312]  Loss_D: 0.00 Loss_G: 4.43 Loss_KL: 0.04 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.87s
                                  
uncon_loss: tensor(2.4090, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(2.0679, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(1.7842, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(1.9158, device='cuda:0', grad_fn=<AddBackward0>)
uncon_loss: tensor(0.9225, device='cuda:0', grad_fn=<AddBackward0>)
cond_loss: tensor(1.7156, device='cuda:0', grad_fn=<AddBackward0>)
uncod_G: tensor(1.9789, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.7583, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.2176, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(3.7970, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(5.0073, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.3104, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(8.1911, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(7.9524, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.1533, device='cuda:0', grad_fn=<MulBackward0>)
[25/600][312]  Loss_D: 11.67 Loss_G: 46.81 Loss_KL: 4.35 lr_g: 0.00020000 lr_d: 0.00002000 Time: 105.35s
                                  
uncod_G: tensor(1.5907, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.1250, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.4169, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(2.3608, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(3.6730, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.4133, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(7.0593, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(6.1165, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(2.5674, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0850, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.3218, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.6836, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0113, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1617, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.5138, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0089, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.3567, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4224, device='cuda:0', grad_fn=<MulBackward0>)
[26/600][312]  Loss_D: 0.00 Loss_G: 4.95 Loss_KL: 0.20 lr_g: 0.00020000 lr_d: 0.00002000 Time: 61.24s
                                  
uncod_G: tensor(0.0539, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4841, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0051, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0983, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4027, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0042, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.3463, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0408, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.8466, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0033, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0662, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.5703, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0021, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1310, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4895, device='cuda:0', grad_fn=<MulBackward0>)
[27/600][312]  Loss_D: 0.00 Loss_G: 4.33 Loss_KL: 0.10 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.58s
                                  
uncod_G: tensor(0.0364, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1070, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2114, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0045, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0705, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1698, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0031, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.1304, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.1691, device='cuda:0', grad_fn=<MulBackward0>)
[28/600][312]  Loss_D: 0.00 Loss_G: 4.47 Loss_KL: 0.06 lr_g: 0.00020000 lr_d: 0.00002000 Time: 60.56s
                                  
uncod_G: tensor(0.0340, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.2091, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0030, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0490, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.0739, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.0636, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0295, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0739, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4496, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0031, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0507, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4239, device='cuda:0', grad_fn=<MulBackward0>)
uncod_G: tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)
con_G: tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
lz_loss tensor(1.4346, device='cuda:0', grad_fn=<MulBackward0>)
[29/600][312]  Loss_D: 0.00 Loss_G: 4.64 Loss_KL: 0.05 lr_g: 0.00020000 lr_d: 0.00002000 Time: 61.16s
                                  
