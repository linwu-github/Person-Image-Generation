nohup: ignoring input
/opt/caoshujian/stack_gan/code/miscc/config.py:101: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
Using config:
{'CONFIG_NAME': '3stages',
 'CUDA': True,
 'DATASET_NAME': 'CUHK',
 'DATA_DIR': 'D:/NEW_HDGAN/StackGAN-v2-master/data/birds',
 'EMBEDDING_TYPE': 'cnn-rnn',
 'GAN': {'B_CONDITION': True,
         'DF_DIM': 64,
         'EMBEDDING_DIM': 128,
         'GF_DIM': 64,
         'NETWORK_TYPE': 'default',
         'R_NUM': 2,
         'Z_DIM': 100},
 'GPU_ID': '0',
 'TEST': {'B_EXAMPLE': True, 'SAMPLE_NUM': 30000},
 'TEXT': {'DIMENSION': 768},
 'TRAIN': {'BATCH_SIZE': 24,
           'COEFF': {'COLOR_LOSS': 0.0,
                     'KL': 2.0,
                     'MS_LOSS': 5.0,
                     'UNCOND_LOSS': 1.0},
           'DISCRIMINATOR_LR': 5e-05,
           'FLAG': True,
           'GENERATOR_LR': 0.0002,
           'MAX_EPOCH': 600,
           'NET_D': '',
           'NET_G': '',
           'SNAPSHOT_INTERVAL': 1000,
           'VIS_COUNT': 64},
 'TREE': {'BASE_SIZE': 64,
          'BASE_SIZE_1': 64,
          'BASE_SIZE_2': 32,
          'BRANCH_NUM': 3},
 'WORKERS': 4}
/home/caoshujian/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Load filenames from: /opt/caoshujian/HD_GAN/Data/train/train_files_1w.pickle (10000)
DataParallel(
  (module): G_NET(
    (ca_net): CA_NET(
      (fc): Linear(in_features=768, out_features=512, bias=True)
      (relu): GLU()
    )
    (h_net1): INIT_STAGE_G(
      (fc): Sequential(
        (0): Linear(in_features=228, out_features=16384, bias=False)
        (1): BatchNorm1d(16384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (upsample1): Sequential(
        (0): Interpolate()
        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample2): Sequential(
        (0): Interpolate()
        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample3): Sequential(
        (0): Interpolate()
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample4): Sequential(
        (0): Interpolate()
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net1): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
    (h_net2): NEXT_STAGE_G(
      (jointConv): Sequential(
        (0): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (residual): Sequential(
        (0): ResBlock(
          (block): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): ResBlock(
          (block): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (upsample): Sequential(
        (0): Interpolate()
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net2): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
    (h_net3): NEXT_STAGE_G(
      (jointConv): Sequential(
        (0): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (residual): Sequential(
        (0): ResBlock(
          (block): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): ResBlock(
          (block): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (upsample): Sequential(
        (0): Interpolate()
        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net3): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
  )
)
# of netsD 3
--------------------
uncon_loss: 2.851562261581421
cond_loss: 3.1664674282073975
--------------------
uncon_loss: 3.0503106117248535
cond_loss: 2.4926581382751465
--------------------
uncon_loss: 2.9530746936798096
cond_loss: 2.577476978302002
--------------------
uncod_G: 1.9249483346939087
con_G: 3.524778127670288
lz_loss 11.161097526550293
--------------------
uncod_G: 1.820065975189209
con_G: 6.458099365234375
lz_loss 10.816813468933105
--------------------
uncod_G: 6.99001932144165
con_G: 8.846770286560059
lz_loss 11.541116714477539
--------------------
uncon_loss: 3.0271947383880615
cond_loss: 2.6735551357269287
--------------------
uncon_loss: 3.084743022918701
cond_loss: 2.656698226928711
--------------------
uncon_loss: 2.498772621154785
cond_loss: 2.5243515968322754
--------------------
uncod_G: 2.154160737991333
con_G: 4.097675323486328
lz_loss 9.001760482788086
--------------------
uncod_G: 3.385432720184326
con_G: 3.3840322494506836
lz_loss 8.823290824890137
--------------------
uncod_G: 3.6878890991210938
con_G: 3.303654432296753
lz_loss 8.498198509216309
--------------------
uncon_loss: 2.9566211700439453
cond_loss: 2.311213254928589
--------------------
uncon_loss: 2.5370497703552246
cond_loss: 2.205758810043335
--------------------
uncon_loss: 2.684813976287842
cond_loss: 2.149196147918701
--------------------
uncod_G: 1.778922438621521
con_G: 3.098513126373291
lz_loss 7.937221527099609
--------------------
uncod_G: 2.701106548309326
con_G: 3.308180332183838
lz_loss 8.788884162902832
--------------------
uncod_G: 4.692752838134766
con_G: 4.0854105949401855
lz_loss 8.600656509399414
[1/600][416]  Loss_D: 15.39 Loss_G: 46.26 Loss_KL: 2.56 lr_g: 0.00020000 lr_d: 0.00005000 Time: 79.97s
                                  
--------------------
uncon_loss: 2.8486924171447754
cond_loss: 2.306406021118164
--------------------
uncon_loss: 2.6365103721618652
cond_loss: 2.2855942249298096
--------------------
uncon_loss: 2.129128932952881
cond_loss: 1.9694757461547852
--------------------
uncod_G: 1.901196002960205
con_G: 2.9622626304626465
lz_loss 9.035223007202148
--------------------
uncod_G: 2.7002289295196533
con_G: 3.352787971496582
lz_loss 8.744739532470703
--------------------
uncod_G: 3.117313861846924
con_G: 3.852418899536133
lz_loss 8.465794563293457
--------------------
uncon_loss: 2.813417911529541
cond_loss: 2.418999195098877
--------------------
uncon_loss: 3.109063148498535
cond_loss: 2.4169821739196777
--------------------
uncon_loss: 2.8749396800994873
cond_loss: 2.419616222381592
--------------------
uncod_G: 1.81174635887146
con_G: 3.149949789047241
lz_loss 8.366334915161133
--------------------
uncod_G: 2.839481830596924
con_G: 3.813230037689209
lz_loss 9.360187530517578
--------------------
uncod_G: 5.442407608032227
con_G: 4.469674110412598
lz_loss 9.822758674621582
[2/600][416]  Loss_D: 15.38 Loss_G: 44.34 Loss_KL: 2.12 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.28s
                                  
--------------------
uncon_loss: 2.7460787296295166
cond_loss: 2.322502613067627
--------------------
uncon_loss: 2.2376835346221924
cond_loss: 2.0973384380340576
--------------------
uncon_loss: 2.161074638366699
cond_loss: 2.1598689556121826
--------------------
uncod_G: 1.8796014785766602
con_G: 2.9830808639526367
lz_loss 7.792482852935791
--------------------
uncod_G: 2.6143717765808105
con_G: 3.7646071910858154
lz_loss 7.647934436798096
--------------------
uncod_G: 5.8231401443481445
con_G: 4.823328018188477
lz_loss 9.30866527557373
--------------------
uncon_loss: 2.831149101257324
cond_loss: 2.4144325256347656
--------------------
uncon_loss: 2.947167158126831
cond_loss: 2.487480640411377
--------------------
uncon_loss: 2.2044506072998047
cond_loss: 2.195366859436035
--------------------
uncod_G: 1.7610714435577393
con_G: 2.786588430404663
lz_loss 8.603633880615234
--------------------
uncod_G: 2.182922840118408
con_G: 2.7699148654937744
lz_loss 9.381247520446777
--------------------
uncod_G: 2.918731212615967
con_G: 3.379220962524414
lz_loss 8.884791374206543
[3/600][416]  Loss_D: 14.96 Loss_G: 44.80 Loss_KL: 1.63 lr_g: 0.00020000 lr_d: 0.00005000 Time: 79.39s
                                  
--------------------
uncon_loss: 2.5398402214050293
cond_loss: 2.3068838119506836
--------------------
uncon_loss: 3.2946455478668213
cond_loss: 2.5531978607177734
--------------------
uncon_loss: 3.607720375061035
cond_loss: 2.393615245819092
--------------------
uncod_G: 1.9409196376800537
con_G: 2.8763551712036133
lz_loss 7.623922348022461
--------------------
uncod_G: 3.299544334411621
con_G: 3.992455005645752
lz_loss 10.181671142578125
--------------------
uncod_G: 5.787983417510986
con_G: 5.1997904777526855
lz_loss 11.109441757202148
--------------------
uncon_loss: 2.9311046600341797
cond_loss: 2.3085789680480957
--------------------
uncon_loss: 2.7614471912384033
cond_loss: 2.158681631088257
--------------------
uncon_loss: 2.650484085083008
cond_loss: 2.271014928817749
--------------------
uncod_G: 1.6604336500167847
con_G: 3.184117317199707
lz_loss 9.018636703491211
--------------------
uncod_G: 2.497135639190674
con_G: 3.385849952697754
lz_loss 9.65720272064209
--------------------
uncod_G: 2.5436758995056152
con_G: 3.217956781387329
lz_loss 10.406761169433594
[4/600][416]  Loss_D: 14.74 Loss_G: 45.21 Loss_KL: 1.40 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.19s
                                  
--------------------
uncon_loss: 2.8682610988616943
cond_loss: 2.0963025093078613
--------------------
uncon_loss: 2.494035482406616
cond_loss: 2.0755560398101807
--------------------
uncon_loss: 2.286403179168701
cond_loss: 2.265181303024292
--------------------
uncod_G: 1.6926860809326172
con_G: 3.1478018760681152
lz_loss 8.0007905960083
--------------------
uncod_G: 1.8767613172531128
con_G: 2.998061180114746
lz_loss 8.435133934020996
--------------------
uncod_G: 6.241158962249756
con_G: 5.04917049407959
lz_loss 8.863371849060059
--------------------
uncon_loss: 2.628422737121582
cond_loss: 2.1279375553131104
--------------------
uncon_loss: 2.649968147277832
cond_loss: 2.014106035232544
--------------------
uncon_loss: 2.390012264251709
cond_loss: 1.958244800567627
--------------------
uncod_G: 1.8326339721679688
con_G: 2.993065357208252
lz_loss 9.286760330200195
--------------------
uncod_G: 2.4928460121154785
con_G: 3.3743343353271484
lz_loss 9.69471549987793
--------------------
uncod_G: 2.363234519958496
con_G: 3.306342840194702
lz_loss 10.552003860473633
[5/600][416]  Loss_D: 14.53 Loss_G: 45.86 Loss_KL: 1.30 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.82s
                                  
--------------------
uncon_loss: 3.013253927230835
cond_loss: 2.353379249572754
--------------------
uncon_loss: 2.323617935180664
cond_loss: 2.274385452270508
--------------------
uncon_loss: 2.655809164047241
cond_loss: 2.3620917797088623
--------------------
uncod_G: 1.6114070415496826
con_G: 2.7939398288726807
lz_loss 9.185754776000977
--------------------
uncod_G: 2.4032695293426514
con_G: 3.1086819171905518
lz_loss 8.884243965148926
--------------------
uncod_G: 5.283458709716797
con_G: 4.682030200958252
lz_loss 8.946720123291016
--------------------
uncon_loss: 2.5147409439086914
cond_loss: 2.443868398666382
--------------------
uncon_loss: 2.1276261806488037
cond_loss: 2.2444422245025635
--------------------
uncon_loss: 2.0900678634643555
cond_loss: 2.094118118286133
--------------------
uncod_G: 1.944109320640564
con_G: 3.24135160446167
lz_loss 9.512956619262695
--------------------
uncod_G: 2.4032421112060547
con_G: 3.040480136871338
lz_loss 8.34111499786377
--------------------
uncod_G: 6.26983642578125
con_G: 5.523954391479492
lz_loss 8.023416519165039
[6/600][416]  Loss_D: 14.45 Loss_G: 46.67 Loss_KL: 1.27 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.40s
                                  
--------------------
uncon_loss: 2.6507434844970703
cond_loss: 2.7316174507141113
--------------------
uncon_loss: 2.7310867309570312
cond_loss: 2.6846423149108887
--------------------
uncon_loss: 2.595195770263672
cond_loss: 2.51739239692688
--------------------
uncod_G: 1.8303697109222412
con_G: 2.9367337226867676
lz_loss 10.725570678710938
--------------------
uncod_G: 2.558959722518921
con_G: 3.280872344970703
lz_loss 11.069217681884766
--------------------
uncod_G: 3.218946695327759
con_G: 4.194690227508545
lz_loss 11.619425773620605
--------------------
uncon_loss: 2.6778321266174316
cond_loss: 2.23175311088562
--------------------
uncon_loss: 2.796938419342041
cond_loss: 2.2843596935272217
--------------------
uncon_loss: 2.0474088191986084
cond_loss: 2.1016392707824707
--------------------
uncod_G: 1.723792314529419
con_G: 3.1088380813598633
lz_loss 9.034632682800293
--------------------
uncod_G: 2.315437078475952
con_G: 3.143315315246582
lz_loss 10.042726516723633
--------------------
uncod_G: 5.561356544494629
con_G: 4.974431991577148
lz_loss 9.980084419250488
[7/600][416]  Loss_D: 14.25 Loss_G: 47.18 Loss_KL: 1.38 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.24s
                                  
--------------------
uncon_loss: 2.903594493865967
cond_loss: 2.5045065879821777
--------------------
uncon_loss: 2.638157844543457
cond_loss: 2.5554211139678955
--------------------
uncon_loss: 2.0788419246673584
cond_loss: 2.395770788192749
--------------------
uncod_G: 1.6117204427719116
con_G: 2.960942029953003
lz_loss 9.536916732788086
--------------------
uncod_G: 2.068394899368286
con_G: 3.0146265029907227
lz_loss 9.54300308227539
--------------------
uncod_G: 4.647035121917725
con_G: 4.78076171875
lz_loss 9.21176815032959
--------------------
uncon_loss: 2.588824510574341
cond_loss: 2.529200553894043
--------------------
uncon_loss: 2.6689112186431885
cond_loss: 2.6068291664123535
--------------------
uncon_loss: 1.6826485395431519
cond_loss: 2.5066182613372803
--------------------
uncod_G: 1.7802119255065918
con_G: 3.002976417541504
lz_loss 10.919977188110352
--------------------
uncod_G: 2.752744674682617
con_G: 3.4661455154418945
lz_loss 11.390886306762695
--------------------
uncod_G: 4.007245063781738
con_G: 4.905805587768555
lz_loss 10.083111763000488
[8/600][416]  Loss_D: 14.17 Loss_G: 48.54 Loss_KL: 1.40 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.84s
                                  
--------------------
uncon_loss: 2.8320131301879883
cond_loss: 2.061645984649658
--------------------
uncon_loss: 2.9854626655578613
cond_loss: 2.1501569747924805
--------------------
uncon_loss: 1.7048592567443848
cond_loss: 1.7218482494354248
--------------------
uncod_G: 1.7292399406433105
con_G: 3.0167083740234375
lz_loss 9.338370323181152
--------------------
uncod_G: 2.151113748550415
con_G: 2.929992198944092
lz_loss 9.963735580444336
--------------------
uncod_G: 3.284278154373169
con_G: 4.222635746002197
lz_loss 9.564538955688477
--------------------
uncon_loss: 2.3687546253204346
cond_loss: 1.9767742156982422
--------------------
uncon_loss: 2.422665596008301
cond_loss: 2.235452175140381
--------------------
uncon_loss: 1.8003416061401367
cond_loss: 2.0214710235595703
--------------------
uncod_G: 1.9087960720062256
con_G: 3.5901682376861572
lz_loss 9.682101249694824
--------------------
uncod_G: 3.195664405822754
con_G: 4.008169174194336
lz_loss 10.474987030029297
--------------------
uncod_G: 5.873487949371338
con_G: 6.1995110511779785
lz_loss 10.33403491973877
[9/600][416]  Loss_D: 13.93 Loss_G: 49.34 Loss_KL: 1.49 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.37s
                                  
--------------------
uncon_loss: 2.5900232791900635
cond_loss: 2.309113025665283
--------------------
uncon_loss: 2.336867094039917
cond_loss: 2.2665224075317383
--------------------
uncon_loss: 1.4702959060668945
cond_loss: 1.6889042854309082
--------------------
uncod_G: 2.0199267864227295
con_G: 3.3334760665893555
lz_loss 9.696747779846191
--------------------
uncod_G: 2.6922693252563477
con_G: 3.676199436187744
lz_loss 11.409341812133789
--------------------
uncod_G: 4.843282699584961
con_G: 5.342958450317383
lz_loss 12.222797393798828
--------------------
uncon_loss: 2.8172450065612793
cond_loss: 2.102245807647705
--------------------
uncon_loss: 3.3070411682128906
cond_loss: 2.3421103954315186
--------------------
uncon_loss: 2.3465371131896973
cond_loss: 2.302353620529175
--------------------
uncod_G: 1.8528952598571777
con_G: 3.1457936763763428
lz_loss 9.221242904663086
--------------------
uncod_G: 2.488703727722168
con_G: 3.2071895599365234
lz_loss 9.512650489807129
--------------------
uncod_G: 6.013002395629883
con_G: 5.986329078674316
lz_loss 9.35483169555664
[10/600][416]  Loss_D: 13.84 Loss_G: 51.13 Loss_KL: 1.97 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.87s
                                  
--------------------
uncon_loss: 2.438577175140381
cond_loss: 2.309361219406128
--------------------
uncon_loss: 2.724031925201416
cond_loss: 2.2790212631225586
--------------------
uncon_loss: 1.8498404026031494
cond_loss: 1.9829463958740234
--------------------
uncod_G: 2.089200973510742
con_G: 2.942687511444092
lz_loss 10.158374786376953
--------------------
uncod_G: 2.4576921463012695
con_G: 3.1165852546691895
lz_loss 10.59911823272705
--------------------
uncod_G: 5.333012580871582
con_G: 5.449089050292969
lz_loss 10.155080795288086
--------------------
uncon_loss: 2.3922691345214844
cond_loss: 2.5184929370880127
--------------------
uncon_loss: 2.2716009616851807
cond_loss: 2.2722415924072266
--------------------
uncon_loss: 1.5654785633087158
cond_loss: 1.9201754331588745
--------------------
uncod_G: 2.1703343391418457
con_G: 3.428952693939209
lz_loss 9.238092422485352
--------------------
uncod_G: 3.814790725708008
con_G: 4.113237380981445
lz_loss 9.177105903625488
--------------------
uncod_G: 6.067805290222168
con_G: 6.457498550415039
lz_loss 10.02698802947998
[11/600][416]  Loss_D: 13.57 Loss_G: 52.16 Loss_KL: 1.76 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.39s
                                  
--------------------
uncon_loss: 2.608370304107666
cond_loss: 2.3511414527893066
--------------------
uncon_loss: 2.6941158771514893
cond_loss: 2.6377432346343994
--------------------
uncon_loss: 1.5655587911605835
cond_loss: 2.059023857116699
--------------------
uncod_G: 1.8119733333587646
con_G: 3.2753047943115234
lz_loss 10.217630386352539
--------------------
uncod_G: 3.2617297172546387
con_G: 4.167619705200195
lz_loss 10.774797439575195
--------------------
uncod_G: 7.59439754486084
con_G: 7.691817283630371
lz_loss 10.736343383789062
--------------------
uncon_loss: 2.677280902862549
cond_loss: 1.8486597537994385
--------------------
uncon_loss: 2.5566048622131348
cond_loss: 1.9626609086990356
--------------------
uncon_loss: 1.9477640390396118
cond_loss: 1.8420320749282837
--------------------
uncod_G: 2.183990001678467
con_G: 3.903374433517456
lz_loss 9.902449607849121
--------------------
uncod_G: 3.408867359161377
con_G: 4.109265327453613
lz_loss 10.790367126464844
--------------------
uncod_G: 4.907136917114258
con_G: 6.0451812744140625
lz_loss 10.042926788330078
[12/600][416]  Loss_D: 13.48 Loss_G: 52.93 Loss_KL: 1.93 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.22s
                                  
--------------------
uncon_loss: 2.610677719116211
cond_loss: 1.9852261543273926
--------------------
uncon_loss: 2.7042839527130127
cond_loss: 2.0923542976379395
--------------------
uncon_loss: 2.037184000015259
cond_loss: 1.9585282802581787
--------------------
uncod_G: 1.736238956451416
con_G: 2.992959976196289
lz_loss 9.832924842834473
--------------------
uncod_G: 4.606639862060547
con_G: 5.08405876159668
lz_loss 9.570024490356445
--------------------
uncod_G: 10.352977752685547
con_G: 9.441394805908203
lz_loss 10.340399742126465
--------------------
uncon_loss: 2.302290916442871
cond_loss: 2.287999391555786
--------------------
uncon_loss: 2.3847334384918213
cond_loss: 2.2153067588806152
--------------------
uncon_loss: 2.0601110458374023
cond_loss: 2.1419029235839844
--------------------
uncod_G: 2.497823715209961
con_G: 4.055243015289307
lz_loss 8.529202461242676
--------------------
uncod_G: 2.886777639389038
con_G: 3.32144832611084
lz_loss 9.385353088378906
--------------------
uncod_G: 6.621694564819336
con_G: 6.023560523986816
lz_loss 8.990396499633789
--------------------
uncon_loss: 2.7029457092285156
cond_loss: 2.271725654602051
--------------------
uncon_loss: 2.8722362518310547
cond_loss: 2.045121669769287
--------------------
uncon_loss: 2.704291820526123
cond_loss: 1.9599409103393555
--------------------
uncod_G: 1.9583539962768555
con_G: 2.902477979660034
lz_loss 10.329856872558594
--------------------
uncod_G: 2.9856386184692383
con_G: 3.872445821762085
lz_loss 10.896483421325684
--------------------
uncod_G: 3.237738609313965
con_G: 4.772069454193115
lz_loss 10.608407020568848
[13/600][416]  Loss_D: 13.48 Loss_G: 53.65 Loss_KL: 2.20 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.87s
                                  
--------------------
uncon_loss: 2.6124107837677
cond_loss: 2.3105428218841553
--------------------
uncon_loss: 2.777273654937744
cond_loss: 2.4649577140808105
--------------------
uncon_loss: 2.7990500926971436
cond_loss: 2.488893985748291
--------------------
uncod_G: 2.057088613510132
con_G: 3.1796212196350098
lz_loss 10.59372329711914
--------------------
uncod_G: 2.7482826709747314
con_G: 2.9931869506835938
lz_loss 12.201613426208496
--------------------
uncod_G: 6.424631118774414
con_G: 6.218698024749756
lz_loss 10.742464065551758
--------------------
uncon_loss: 1.7369110584259033
cond_loss: 1.9048620462417603
--------------------
uncon_loss: 2.2471446990966797
cond_loss: 1.968200445175171
--------------------
uncon_loss: 1.8866339921951294
cond_loss: 2.256108522415161
--------------------
uncod_G: 2.644166946411133
con_G: 4.43477201461792
lz_loss 8.776226997375488
--------------------
uncod_G: 4.024849891662598
con_G: 4.681081771850586
lz_loss 9.340703010559082
--------------------
uncod_G: 6.901810646057129
con_G: 6.850225448608398
lz_loss 10.95448112487793
[14/600][416]  Loss_D: 13.26 Loss_G: 55.68 Loss_KL: 2.37 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.38s
                                  
--------------------
uncon_loss: 2.4061086177825928
cond_loss: 2.0273380279541016
--------------------
uncon_loss: 2.08070969581604
cond_loss: 1.9609324932098389
--------------------
uncon_loss: 1.8510710000991821
cond_loss: 2.167468547821045
--------------------
uncod_G: 2.039992094039917
con_G: 3.5463898181915283
lz_loss 11.21767807006836
--------------------
uncod_G: 3.2074637413024902
con_G: 4.010326385498047
lz_loss 11.209507942199707
--------------------
uncod_G: 12.009481430053711
con_G: 11.496295928955078
lz_loss 9.787751197814941
--------------------
uncon_loss: 2.1177735328674316
cond_loss: 2.016681671142578
--------------------
uncon_loss: 2.2058305740356445
cond_loss: 2.073004961013794
--------------------
uncon_loss: 1.7349045276641846
cond_loss: 2.0388472080230713
--------------------
uncod_G: 2.268171787261963
con_G: 3.5925471782684326
lz_loss 9.802002906799316
--------------------
uncod_G: 4.072669982910156
con_G: 4.652433395385742
lz_loss 10.495330810546875
--------------------
uncod_G: 9.21561050415039
con_G: 8.670578002929688
lz_loss 10.113338470458984
[15/600][416]  Loss_D: 13.32 Loss_G: 56.38 Loss_KL: 2.48 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.79s
                                  
--------------------
uncon_loss: 2.8489205837249756
cond_loss: 2.0974087715148926
--------------------
uncon_loss: 2.6500556468963623
cond_loss: 2.5455846786499023
--------------------
uncon_loss: 1.710423231124878
cond_loss: 2.546156883239746
--------------------
uncod_G: 2.3904833793640137
con_G: 3.8758656978607178
lz_loss 10.721236228942871
--------------------
uncod_G: 3.065873861312866
con_G: 4.274320602416992
lz_loss 10.929275512695312
--------------------
uncod_G: 5.794584274291992
con_G: 7.465285301208496
lz_loss 10.353736877441406
--------------------
uncon_loss: 3.14890193939209
cond_loss: 2.079911708831787
--------------------
uncon_loss: 2.813783645629883
cond_loss: 2.2372946739196777
--------------------
uncon_loss: 1.8675591945648193
cond_loss: 2.1501994132995605
--------------------
uncod_G: 1.8641889095306396
con_G: 3.3765721321105957
lz_loss 10.308502197265625
--------------------
uncod_G: 3.509442090988159
con_G: 3.8531315326690674
lz_loss 10.173580169677734
--------------------
uncod_G: 8.629166603088379
con_G: 7.8749871253967285
lz_loss 9.126805305480957
[16/600][416]  Loss_D: 13.35 Loss_G: 56.89 Loss_KL: 2.54 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.36s
                                  
--------------------
uncon_loss: 3.0798730850219727
cond_loss: 2.7300846576690674
--------------------
uncon_loss: 2.5877573490142822
cond_loss: 2.377429962158203
--------------------
uncon_loss: 1.8258097171783447
cond_loss: 1.8556466102600098
--------------------
uncod_G: 2.047563076019287
con_G: 3.2886252403259277
lz_loss 10.273905754089355
--------------------
uncod_G: 3.8534963130950928
con_G: 4.344200134277344
lz_loss 10.88270378112793
--------------------
uncod_G: 9.998735427856445
con_G: 9.026002883911133
lz_loss 10.608491897583008
--------------------
uncon_loss: 2.7778449058532715
cond_loss: 1.9273606538772583
--------------------
uncon_loss: 2.410834312438965
cond_loss: 2.034231424331665
--------------------
uncon_loss: 1.4470829963684082
cond_loss: 1.740034818649292
--------------------
uncod_G: 2.197092056274414
con_G: 3.7109429836273193
lz_loss 10.897756576538086
--------------------
uncod_G: 3.582904577255249
con_G: 4.161077499389648
lz_loss 12.469854354858398
--------------------
uncod_G: 5.691230773925781
con_G: 6.904415130615234
lz_loss 10.462101936340332
[17/600][416]  Loss_D: 13.36 Loss_G: 57.76 Loss_KL: 2.59 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.85s
                                  
--------------------
uncon_loss: 2.8004140853881836
cond_loss: 2.193537473678589
--------------------
uncon_loss: 2.505859375
cond_loss: 2.0572266578674316
--------------------
uncon_loss: 1.7976996898651123
cond_loss: 1.6823997497558594
--------------------
uncod_G: 2.32378888130188
con_G: 3.1137475967407227
lz_loss 9.928873062133789
--------------------
uncod_G: 5.142517566680908
con_G: 5.227809906005859
lz_loss 9.4833984375
--------------------
uncod_G: 8.471015930175781
con_G: 7.665585041046143
lz_loss 9.79649543762207
--------------------
uncon_loss: 2.2398440837860107
cond_loss: 2.120387554168701
--------------------
uncon_loss: 2.5951967239379883
cond_loss: 2.2484545707702637
--------------------
uncon_loss: 1.757926106452942
cond_loss: 1.6584255695343018
--------------------
uncod_G: 1.9873403310775757
con_G: 2.9163522720336914
lz_loss 10.450916290283203
--------------------
uncod_G: 5.211636543273926
con_G: 5.2364501953125
lz_loss 11.0847749710083
--------------------
uncod_G: 6.305498123168945
con_G: 5.906284332275391
lz_loss 11.867112159729004
[18/600][416]  Loss_D: 13.14 Loss_G: 57.79 Loss_KL: 3.17 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.35s
                                  
--------------------
uncon_loss: 2.3421664237976074
cond_loss: 2.4655773639678955
--------------------
uncon_loss: 2.631517171859741
cond_loss: 2.41505765914917
--------------------
uncon_loss: 1.9433503150939941
cond_loss: 1.9012749195098877
--------------------
uncod_G: 2.729712963104248
con_G: 3.966576337814331
lz_loss 11.021088600158691
--------------------
uncod_G: 3.7796144485473633
con_G: 3.9903316497802734
lz_loss 11.658197402954102
--------------------
uncod_G: 10.984166145324707
con_G: 8.942351341247559
lz_loss 10.687767028808594
--------------------
uncon_loss: 2.434734344482422
cond_loss: 2.2212417125701904
--------------------
uncon_loss: 2.1265406608581543
cond_loss: 2.1765148639678955
--------------------
uncon_loss: 1.5783518552780151
cond_loss: 1.759788990020752
--------------------
uncod_G: 1.8938894271850586
con_G: 2.9533891677856445
lz_loss 10.237264633178711
--------------------
uncod_G: 4.074306488037109
con_G: 4.814321994781494
lz_loss 10.082866668701172
--------------------
uncod_G: 5.751895904541016
con_G: 6.3942484855651855
lz_loss 10.85192584991455
[19/600][416]  Loss_D: 12.95 Loss_G: 59.26 Loss_KL: 3.48 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.40s
                                  
--------------------
uncon_loss: 2.3095812797546387
cond_loss: 2.1284825801849365
--------------------
uncon_loss: 2.1588118076324463
cond_loss: 1.94534432888031
--------------------
uncon_loss: 1.619550347328186
cond_loss: 2.0939416885375977
--------------------
uncod_G: 2.6774144172668457
con_G: 3.8204169273376465
lz_loss 11.682552337646484
--------------------
uncod_G: 3.540436267852783
con_G: 3.9172959327697754
lz_loss 11.828664779663086
--------------------
uncod_G: 10.456953048706055
con_G: 9.317177772521973
lz_loss 11.535646438598633
--------------------
uncon_loss: 2.6265954971313477
cond_loss: 2.2038753032684326
--------------------
uncon_loss: 2.4565138816833496
cond_loss: 2.035048484802246
--------------------
uncon_loss: 1.6718652248382568
cond_loss: 1.9996302127838135
--------------------
uncod_G: 2.1129515171051025
con_G: 3.4253270626068115
lz_loss 9.617493629455566
--------------------
uncod_G: 4.5158796310424805
con_G: 5.198446273803711
lz_loss 11.046293258666992
--------------------
uncod_G: 7.052571773529053
con_G: 6.363763332366943
lz_loss 11.4154052734375
[20/600][416]  Loss_D: 12.98 Loss_G: 59.47 Loss_KL: 3.93 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.97s
                                  
--------------------
uncon_loss: 2.4343109130859375
cond_loss: 2.1709766387939453
--------------------
uncon_loss: 1.8779561519622803
cond_loss: 1.924028754234314
--------------------
uncon_loss: 2.0885961055755615
cond_loss: 2.027470111846924
--------------------
uncod_G: 2.191020965576172
con_G: 3.583347797393799
lz_loss 10.911608695983887
--------------------
uncod_G: 4.472480773925781
con_G: 5.2922773361206055
lz_loss 11.97439956665039
--------------------
uncod_G: 11.713005065917969
con_G: 11.26346492767334
lz_loss 10.76664924621582
--------------------
uncon_loss: 2.6808347702026367
cond_loss: 1.9062849283218384
--------------------
uncon_loss: 3.111290693283081
cond_loss: 2.3450632095336914
--------------------
uncon_loss: 2.1560254096984863
cond_loss: 2.681952714920044
--------------------
uncod_G: 2.0065343379974365
con_G: 3.4045071601867676
lz_loss 9.067419052124023
--------------------
uncod_G: 2.279331922531128
con_G: 3.034937858581543
lz_loss 10.31409740447998
--------------------
uncod_G: 4.345607280731201
con_G: 4.858489036560059
lz_loss 10.372124671936035
[21/600][416]  Loss_D: 13.02 Loss_G: 60.29 Loss_KL: 4.04 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.27s
                                  
--------------------
uncon_loss: 2.4116647243499756
cond_loss: 1.9824773073196411
--------------------
uncon_loss: 2.223231077194214
cond_loss: 2.0574440956115723
--------------------
uncon_loss: 1.8461005687713623
cond_loss: 1.9227874279022217
--------------------
uncod_G: 2.227559804916382
con_G: 3.392285108566284
lz_loss 12.152508735656738
--------------------
uncod_G: 3.5959784984588623
con_G: 4.164847373962402
lz_loss 12.7459135055542
--------------------
uncod_G: 5.701129913330078
con_G: 6.000222206115723
lz_loss 13.08067512512207
--------------------
uncon_loss: 3.292117118835449
cond_loss: 2.1104226112365723
--------------------
uncon_loss: 2.243384838104248
cond_loss: 2.286349058151245
--------------------
uncon_loss: 1.300472378730774
cond_loss: 1.722707748413086
--------------------
uncod_G: 1.5475271940231323
con_G: 2.920846462249756
lz_loss 11.012443542480469
--------------------
uncod_G: 2.930896759033203
con_G: 4.2186126708984375
lz_loss 10.54438591003418
--------------------
uncod_G: 11.21859359741211
con_G: 10.451997756958008
lz_loss 10.4254150390625
[22/600][416]  Loss_D: 12.68 Loss_G: 62.12 Loss_KL: 4.32 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.89s
                                  
--------------------
uncon_loss: 2.7408013343811035
cond_loss: 2.4607038497924805
--------------------
uncon_loss: 2.337127447128296
cond_loss: 2.3873727321624756
--------------------
uncon_loss: 1.1410915851593018
cond_loss: 1.751334309577942
--------------------
uncod_G: 2.439249038696289
con_G: 4.023470401763916
lz_loss 12.393412590026855
--------------------
uncod_G: 5.230511665344238
con_G: 6.018003463745117
lz_loss 11.900453567504883
--------------------
uncod_G: 10.86277961730957
con_G: 10.60297679901123
lz_loss 12.472402572631836
--------------------
uncon_loss: 2.534526824951172
cond_loss: 2.3497061729431152
--------------------
uncon_loss: 2.303494453430176
cond_loss: 2.408766508102417
--------------------
uncon_loss: 1.3215653896331787
cond_loss: 2.203251361846924
--------------------
uncod_G: 2.4104933738708496
con_G: 3.823361396789551
lz_loss 11.892457962036133
--------------------
uncod_G: 5.125171661376953
con_G: 5.658783435821533
lz_loss 12.860940933227539
--------------------
uncod_G: 8.883264541625977
con_G: 8.341485977172852
lz_loss 11.387816429138184
[23/600][416]  Loss_D: 12.83 Loss_G: 62.86 Loss_KL: 4.33 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.45s
                                  
--------------------
uncon_loss: 2.6236934661865234
cond_loss: 1.6751374006271362
--------------------
uncon_loss: 2.5928845405578613
cond_loss: 1.8402111530303955
--------------------
uncon_loss: 2.629622220993042
cond_loss: 2.222310781478882
--------------------
uncod_G: 2.253669500350952
con_G: 3.7228829860687256
lz_loss 9.504881858825684
--------------------
uncod_G: 2.5386805534362793
con_G: 3.484506607055664
lz_loss 11.109171867370605
--------------------
uncod_G: 5.877322196960449
con_G: 6.84928560256958
lz_loss 10.802054405212402
--------------------
uncon_loss: 3.0135746002197266
cond_loss: 2.154039144515991
--------------------
uncon_loss: 2.249037265777588
cond_loss: 2.0763230323791504
--------------------
uncon_loss: 1.6062349081039429
cond_loss: 1.9857721328735352
--------------------
uncod_G: 1.8773829936981201
con_G: 3.4895310401916504
lz_loss 10.607794761657715
--------------------
uncod_G: 3.152336597442627
con_G: 3.9585869312286377
lz_loss 11.401062965393066
--------------------
uncod_G: 11.151891708374023
con_G: 10.707015037536621
lz_loss 10.622552871704102
[24/600][416]  Loss_D: 12.54 Loss_G: 63.89 Loss_KL: 4.48 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.44s
                                  
--------------------
uncon_loss: 2.2585175037384033
cond_loss: 2.123688220977783
--------------------
uncon_loss: 2.07367205619812
cond_loss: 1.9585442543029785
--------------------
uncon_loss: 1.0101426839828491
cond_loss: 1.8375425338745117
--------------------
uncod_G: 2.17707896232605
con_G: 3.2802953720092773
lz_loss 10.43474292755127
--------------------
uncod_G: 4.10398006439209
con_G: 4.802614688873291
lz_loss 11.571622848510742
--------------------
uncod_G: 6.583593845367432
con_G: 6.736225128173828
lz_loss 11.159415245056152
--------------------
uncon_loss: 3.5989551544189453
cond_loss: 2.8173463344573975
--------------------
uncon_loss: 2.4866557121276855
cond_loss: 2.3786702156066895
--------------------
uncon_loss: 1.716443419456482
cond_loss: 2.721222400665283
--------------------
uncod_G: 1.837249994277954
con_G: 2.9706339836120605
lz_loss 10.35486125946045
--------------------
uncod_G: 4.207997798919678
con_G: 4.594594955444336
lz_loss 11.526566505432129
--------------------
uncod_G: 11.265289306640625
con_G: 9.895798683166504
lz_loss 11.364750862121582
[25/600][416]  Loss_D: 12.26 Loss_G: 64.46 Loss_KL: 5.08 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.86s
                                  
--------------------
uncon_loss: 2.352862596511841
cond_loss: 2.096909761428833
--------------------
uncon_loss: 1.9417234659194946
cond_loss: 1.6772911548614502
--------------------
uncon_loss: 1.3033835887908936
cond_loss: 1.8045836687088013
--------------------
uncod_G: 2.126307964324951
con_G: 3.5421438217163086
lz_loss 10.014181137084961
--------------------
uncod_G: 3.577772617340088
con_G: 4.972118377685547
lz_loss 10.401030540466309
--------------------
uncod_G: 5.966442108154297
con_G: 5.655411720275879
lz_loss 9.564080238342285
--------------------
uncon_loss: 2.2816615104675293
cond_loss: 2.037889242172241
--------------------
uncon_loss: 2.169188976287842
cond_loss: 2.278120517730713
--------------------
uncon_loss: 1.2550736665725708
cond_loss: 1.2204630374908447
--------------------
uncod_G: 2.217557430267334
con_G: 3.9872381687164307
lz_loss 10.318426132202148
--------------------
uncod_G: 5.454400062561035
con_G: 6.029564380645752
lz_loss 11.018959045410156
--------------------
uncod_G: 10.744786262512207
con_G: 10.557353973388672
lz_loss 11.270308494567871
--------------------
uncon_loss: 2.369292974472046
cond_loss: 1.9189300537109375
--------------------
uncon_loss: 2.0501770973205566
cond_loss: 2.0451653003692627
--------------------
uncon_loss: 0.9195643663406372
cond_loss: 1.8471890687942505
--------------------
uncod_G: 2.330179214477539
con_G: 4.261814117431641
lz_loss 10.401432037353516
--------------------
uncod_G: 3.945869207382202
con_G: 5.046529293060303
lz_loss 9.684813499450684
--------------------
uncod_G: 7.2086944580078125
con_G: 7.654829025268555
lz_loss 10.524720191955566
[26/600][416]  Loss_D: 12.19 Loss_G: 65.63 Loss_KL: 5.37 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.47s
                                  
--------------------
uncon_loss: 2.02681827545166
cond_loss: 1.8487884998321533
--------------------
uncon_loss: 1.7181882858276367
cond_loss: 1.551627516746521
--------------------
uncon_loss: 0.6930907368659973
cond_loss: 1.5965981483459473
--------------------
uncod_G: 2.2993083000183105
con_G: 3.697296380996704
lz_loss 11.639100074768066
--------------------
uncod_G: 3.3936808109283447
con_G: 4.6454057693481445
lz_loss 12.001392364501953
--------------------
uncod_G: 6.47150993347168
con_G: 7.949540138244629
lz_loss 11.93795394897461
--------------------
uncon_loss: 1.9363573789596558
cond_loss: 2.1367175579071045
--------------------
uncon_loss: 1.689794659614563
cond_loss: 2.249600887298584
--------------------
uncon_loss: 1.3108669519424438
cond_loss: 1.779052734375
--------------------
uncod_G: 2.708716869354248
con_G: 4.303733825683594
lz_loss 10.006948471069336
--------------------
uncod_G: 5.873051643371582
con_G: 6.052923202514648
lz_loss 10.485980987548828
--------------------
uncod_G: 14.514860153198242
con_G: 12.92880630493164
lz_loss 11.514200210571289
[27/600][416]  Loss_D: 11.98 Loss_G: 67.22 Loss_KL: 5.65 lr_g: 0.00020000 lr_d: 0.00005000 Time: 78.90s
                                  
