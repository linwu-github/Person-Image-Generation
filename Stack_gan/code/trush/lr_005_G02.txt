nohup: ignoring input
/opt/caoshujian/stack_gan/code/miscc/config.py:101: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  yaml_cfg = edict(yaml.load(f))
Using config:
{'CONFIG_NAME': '3stages',
 'CUDA': True,
 'DATASET_NAME': 'CUHK',
 'DATA_DIR': 'D:/NEW_HDGAN/StackGAN-v2-master/data/birds',
 'EMBEDDING_TYPE': 'cnn-rnn',
 'GAN': {'B_CONDITION': True,
         'DF_DIM': 64,
         'EMBEDDING_DIM': 128,
         'GF_DIM': 64,
         'NETWORK_TYPE': 'default',
         'R_NUM': 2,
         'Z_DIM': 100},
 'GPU_ID': '0',
 'TEST': {'B_EXAMPLE': True, 'SAMPLE_NUM': 30000},
 'TEXT': {'DIMENSION': 768},
 'TRAIN': {'BATCH_SIZE': 36,
           'COEFF': {'COLOR_LOSS': 0.0, 'KL': 2.0, 'UNCOND_LOSS': 1.0},
           'DISCRIMINATOR_LR': 5e-05,
           'FLAG': True,
           'GENERATOR_LR': 0.0002,
           'MAX_EPOCH': 600,
           'NET_D': '',
           'NET_G': '',
           'SNAPSHOT_INTERVAL': 1000,
           'VIS_COUNT': 64},
 'TREE': {'BASE_SIZE': 64,
          'BASE_SIZE_1': 64,
          'BASE_SIZE_2': 32,
          'BRANCH_NUM': 3},
 'WORKERS': 4}
/home/caoshujian/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
Load filenames from: /opt/caoshujian/HD_GAN/Data/train/train_files_1w.pickle (10000)
DataParallel(
  (module): G_NET(
    (ca_net): CA_NET(
      (fc): Linear(in_features=768, out_features=512, bias=True)
      (relu): GLU()
    )
    (h_net1): INIT_STAGE_G(
      (fc): Sequential(
        (0): Linear(in_features=228, out_features=16384, bias=False)
        (1): BatchNorm1d(16384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (upsample1): Sequential(
        (0): Interpolate()
        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample2): Sequential(
        (0): Interpolate()
        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample3): Sequential(
        (0): Interpolate()
        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
      (upsample4): Sequential(
        (0): Interpolate()
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net1): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
    (h_net2): NEXT_STAGE_G(
      (jointConv): Sequential(
        (0): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (residual): Sequential(
        (0): ResBlock(
          (block): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): ResBlock(
          (block): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (upsample): Sequential(
        (0): Interpolate()
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net2): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
    (h_net3): NEXT_STAGE_G(
      (jointConv): Sequential(
        (0): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GLU()
      )
      (residual): Sequential(
        (0): ResBlock(
          (block): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): ResBlock(
          (block): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): GLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (upsample): Sequential(
        (0): Interpolate()
        (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): GLU()
      )
    )
    (img_net3): GET_IMAGE_G(
      (img): Sequential(
        (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): Tanh()
      )
    )
  )
)
# of netsD 3
[1/600][277] Loss_D: 9.32 Loss_G: 16.72 Loss_KL: 1.16 lr_g: 0.00020000 lr_d: 0.00005000 Time: 72.38s
                                  
[2/600][277] Loss_D: 9.22 Loss_G: 11.72 Loss_KL: 1.10 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.89s
                                  
[3/600][277] Loss_D: 9.36 Loss_G: 12.75 Loss_KL: 1.16 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.90s
                                  
[4/600][277] Loss_D: 7.79 Loss_G: 19.82 Loss_KL: 1.46 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.79s
                                  
[5/600][277] Loss_D: 9.10 Loss_G: 26.44 Loss_KL: 1.53 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.92s
                                  
[6/600][277] Loss_D: 8.16 Loss_G: 22.59 Loss_KL: 1.48 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.97s
                                  
[7/600][277] Loss_D: 7.37 Loss_G: 14.69 Loss_KL: 1.73 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.95s
                                  
[8/600][277] Loss_D: 7.31 Loss_G: 21.12 Loss_KL: 1.77 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.74s
                                  
[9/600][277] Loss_D: 10.83 Loss_G: 18.87 Loss_KL: 2.08 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.94s
                                  
[10/600][277] Loss_D: 6.25 Loss_G: 23.95 Loss_KL: 2.15 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.93s
                                  
[11/600][277] Loss_D: 5.97 Loss_G: 26.66 Loss_KL: 1.91 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.70s
                                  
[12/600][277] Loss_D: 6.84 Loss_G: 18.65 Loss_KL: 2.10 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.07s
                                  
[13/600][277] Loss_D: 5.28 Loss_G: 17.25 Loss_KL: 2.55 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.94s
                                  
[14/600][277] Loss_D: 6.61 Loss_G: 21.67 Loss_KL: 2.68 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.22s
                                  
[15/600][277] Loss_D: 7.72 Loss_G: 37.39 Loss_KL: 2.97 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.72s
                                  
[16/600][277] Loss_D: 5.10 Loss_G: 21.80 Loss_KL: 3.18 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.99s
                                  
[17/600][277] Loss_D: 4.15 Loss_G: 22.11 Loss_KL: 3.46 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.88s
                                  
[18/600][277] Loss_D: 7.14 Loss_G: 28.05 Loss_KL: 3.84 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.94s
                                  
[19/600][277] Loss_D: 4.37 Loss_G: 22.95 Loss_KL: 3.32 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.67s
                                  
[20/600][277] Loss_D: 4.29 Loss_G: 18.62 Loss_KL: 3.50 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.25s
                                  
[21/600][277] Loss_D: 4.52 Loss_G: 20.68 Loss_KL: 3.88 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.04s
                                  
[22/600][277] Loss_D: 6.17 Loss_G: 27.26 Loss_KL: 3.84 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.71s
                                  
[23/600][277] Loss_D: 6.49 Loss_G: 24.00 Loss_KL: 3.99 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.05s
                                  
[24/600][277] Loss_D: 5.21 Loss_G: 33.69 Loss_KL: 3.99 lr_g: 0.00020000 lr_d: 0.00005000 Time: 69.99s
                                  
[25/600][277] Loss_D: 10.64 Loss_G: 39.46 Loss_KL: 3.51 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.23s
                                  
[26/600][277] Loss_D: 3.57 Loss_G: 34.52 Loss_KL: 3.68 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.69s
                                  
[27/600][277] Loss_D: 5.00 Loss_G: 30.56 Loss_KL: 4.38 lr_g: 0.00020000 lr_d: 0.00005000 Time: 70.07s
                                  
